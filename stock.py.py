# -*- coding: utf-8 -*-
"""Untitled53.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t8LvMF3l-zkFwRCSJrCK94vWc2bOIyOa
"""

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta

plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)
sns.set_palette('viridis')

stocks = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA', 'NVDA', 'META', 'BRK-B', 'JPM', 'JNJ']
end_date = datetime.today().strftime('%Y-%m-%d')
start_date = (datetime.today() - timedelta(days=5*365)).strftime('%Y-%m-%d')  # 5 years of data

stock_data = yf.download(stocks, start=start_date, end=end_date)['Close']

# Display data
print(f"Collected data for {len(stocks)} stocks from {start_date} to {end_date}")
print(f"Data shape: {stock_data.shape}")
stock_data.head()

# Calculate daily returns
returns = stock_data.pct_change().dropna()

# Calculate actual 5-day forward returns for each stock individually
for stock in stocks:
    returns[f'{stock}_Actual_5d_Return'] = stock_data[stock].pct_change(5).shift(-5)

# Calculate overall actual return (average across all stocks)
returns['Actual_5d_Return'] = returns[[f'{stock}_Actual_5d_Return' for stock in stocks]].mean(axis=1)

# Display returns data
print("\nDaily returns data:")
returns.head()

plt.figure(figsize=(14, 10))
for i, stock in enumerate(stocks, 1):
    plt.subplot(3, 4, i)
    sns.histplot(returns[stock], bins=50, kde=True)
    plt.title(f"{stock} Daily Returns")
    plt.xlabel('Return')
plt.tight_layout()
plt.show()

# Technical indicators
def calculate_technical_indicators(data):
    # Moving averages
    data['MA_5'] = data.rolling(window=5).mean()
    data['MA_20'] = data.rolling(window=20).mean()

    # Bollinger Bands
    data['BB_upper'] = data['MA_20'] + 2 * data.rolling(window=20).std()
    data['BB_lower'] = data['MA_20'] - 2 * data.rolling(window=20).std()

    # Relative Strength Index (RSI)
    delta = data.diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=14).mean()
    avg_loss = loss.rolling(window=14).mean()
    rs = avg_gain / avg_loss
    data['RSI'] = 100 - (100 / (1 + rs))

    # MACD
    ema12 = data.ewm(span=12, adjust=False).mean()
    ema26 = data.ewm(span=26, adjust=False).mean()
    data['MACD'] = ema12 - ema26
    data['Signal_Line'] = data['MACD'].ewm(span=9, adjust=False).mean()

    # Price Rate of Change
    data['ROC'] = data.pct_change(periods=5)

    return data

# First, ensure all our price data is numeric
stock_data = stock_data.apply(pd.to_numeric, errors='coerce')

# Calculate daily returns properly
returns = pd.DataFrame()
for stock in stocks:
    returns[stock] = stock_data[stock].pct_change()

# Calculate 5-day forward returns for each stock
forward_returns = pd.DataFrame()
for stock in stocks:
    forward_returns[f'{stock}_Actual_5d_Return'] = stock_data[stock].pct_change(5).shift(-5)

# Combine into single returns DataFrame
returns = pd.concat([returns, forward_returns], axis=1).dropna()

# Technical Indicators Calculation (fixed version)
def calculate_technical_indicators(price_series):
    """
    Calculate technical indicators for a single stock price series
    Returns a DataFrame with all indicators
    """
    indicators = pd.DataFrame(index=price_series.index)
    price_values = price_series.values

    # Simple Moving Averages
    indicators['MA_5'] = price_series.rolling(window=5).mean()
    indicators['MA_20'] = price_series.rolling(window=20).mean()

    # Bollinger Bands
    rolling_std = price_series.rolling(window=20).std()
    indicators['BB_upper'] = indicators['MA_20'] + (2 * rolling_std)
    indicators['BB_lower'] = indicators['MA_20'] - (2 * rolling_std)

    # RSI
    delta = price_series.diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)

    avg_gain = gain.rolling(window=14).mean()
    avg_loss = loss.rolling(window=14).mean()

    rs = avg_gain / avg_loss
    indicators['RSI'] = 100 - (100 / (1 + rs))

    # MACD
    ema12 = price_series.ewm(span=12, adjust=False).mean()
    ema26 = price_series.ewm(span=26, adjust=False).mean()
    indicators['MACD'] = ema12 - ema26
    indicators['Signal_Line'] = indicators['MACD'].ewm(span=9, adjust=False).mean()

    # Rate of Change
    indicators['ROC'] = price_series.pct_change(periods=5)

    return indicators

# Calculate indicators for each stock
all_indicators = {}
for stock in stocks:
    all_indicators[stock] = calculate_technical_indicators(stock_data[stock])

# Combine indicators into main returns DataFrame
for stock in stocks:
    indicators = all_indicators[stock]
    for col in indicators.columns:
        returns[f'{stock}_{col}'] = indicators[col]

# Add market return (S&P 500)
sp500 = yf.download('^GSPC', start=start_date, end=end_date)['Close']
returns['Market_Return'] = sp500.pct_change()

# Add volatility measure
returns['Volatility'] = returns[stocks].std(axis=1)

# Create lag features
for stock in stocks:
    for lag in [1, 2, 3, 5]:
        returns[f'{stock}_lag{lag}'] = returns[stock].shift(lag)

# Calculate overall actual return (average across all stocks)
returns['Actual_5d_Return'] = returns[[f'{stock}_Actual_5d_Return' for stock in stocks]].mean(axis=1)

# Clean up - drop any remaining NA values
returns.dropna(inplace=True)

# Display the final prepared data
print("\nFinal prepared dataset:")
print(f"Shape: {returns.shape}")
returns.head()

def evaluate_model(y_true, y_pred, model_name):
    """Enhanced evaluation function with NaN handling"""
    # Align and drop NA values
    df = pd.DataFrame({'true': y_true, 'pred': y_pred}).dropna()
    if len(df) == 0:
        raise ValueError("No valid data points after NA removal")

    y_true = df['true']
    y_pred = df['pred']

    # Rest of your evaluation code...
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    print(f"{model_name} Performance:")
    print(f"  MSE: {mse:.6f}")
    print(f"  MAE: {mae:.6f}")
    print(f"  R²: {r2:.4f}")

    # Plotting code...
    plt.figure(figsize=(10, 6))
    plt.scatter(y_true, y_pred, alpha=0.3)
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')
    plt.xlabel('Actual Returns')
    plt.ylabel('Predicted Returns')
    plt.title(f'{model_name} Predictions vs Actual')
    plt.show()

    return mse, mae, r2

print("## Baseline Model 1: Historical Mean ##")
historical_mean = returns[stocks].mean().mean()
mean_predictions = [historical_mean] * len(returns)
mean_perf = evaluate_model(returns['Actual_5d_Return'], mean_predictions, "Historical Mean")

# Model 2: Last Return (Naive Forecast)
print("\n## Baseline Model 2: Last Return ##")
last_return_predictions = returns[stocks].shift(1).mean(axis=1)
last_return_perf = evaluate_model(returns['Actual_5d_Return'], last_return_predictions, "Last Return")

# Model 3: Linear Regression
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

print("\n## Model 3: Linear Regression ##")

# Prepare features and target
features = [f'{stock}_lag1' for stock in stocks] + ['Market_Return', 'Volatility']
X = returns[features]
y = returns['Actual_5d_Return']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=False, random_state=42
)

# Train model
lr = LinearRegression()
lr.fit(X_train, y_train)

# Predict and evaluate
lr_predictions = lr.predict(X_test)
lr_perf = evaluate_model(y_test, lr_predictions, "Linear Regression")

# Model 4: Random Forest
from sklearn.ensemble import RandomForestRegressor

print("\n## Model 4: Random Forest ##")

rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

rf_predictions = rf.predict(X_test)
rf_perf = evaluate_model(y_test, rf_predictions, "Random Forest")

# Feature importance
feature_imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(12, 6))
sns.barplot(x=feature_imp, y=feature_imp.index)
plt.title("Random Forest Feature Importance")
plt.show()

# Model 5: XGBoost
from xgboost import XGBRegressor

print("\n## Model 5: XGBoost ##")

xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, random_state=42)
xgb.fit(X_train, y_train)

xgb_predictions = xgb.predict(X_test)
xgb_perf = evaluate_model(y_test, xgb_predictions, "XGBoost")

from lightgbm import LGBMRegressor

print("\n## Model 6: LightGBM ##")

lgbm = LGBMRegressor(n_estimators=200, learning_rate=0.05, random_state=42)
lgbm.fit(X_train, y_train)

lgbm_predictions = lgbm.predict(X_test)
lgbm_perf = evaluate_model(y_test, lgbm_predictions, "LightGBM")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import MinMaxScaler

# Prepare data for LSTM
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length, -1])  # Last column is target
    return np.array(X), np.array(y)

scaler = MinMaxScaler(feature_range=(-1, 1))
scaled_data = scaler.fit_transform(returns[features + ['Actual_5d_Return']])

# Create sequences
seq_length = 10
X_seq, y_seq = create_sequences(scaled_data, seq_length)

# Train-test split
split = int(0.8 * len(X_seq))
X_train_seq, X_test_seq = X_seq[:split], X_seq[split:]
y_train_seq, y_test_seq = y_seq[:split], y_seq[split:]

model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(seq_length, len(features)+1)),
    Dropout(0.2),
    LSTM(32),
    Dropout(0.2),
    Dense(16, activation='relu'),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse')
# Train model
print("\n## Training LSTM Model ##")
history = model.fit(
    X_train_seq, y_train_seq,
    epochs=50,
    batch_size=32,
    validation_split=0.1,
    verbose=1
)

# Plot training history
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('LSTM Training History')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

lstm_predictions = model.predict(X_test_seq).flatten()
lstm_perf = evaluate_model(y_test_seq, lstm_predictions, "LSTM")

# Compile performance metrics
model_names = [
    "Historical Mean", "Last Return", "Linear Regression",
    "Random Forest", "XGBoost", "LightGBM", "LSTM"
]
performance = [
    mean_perf, last_return_perf, lr_perf,
    rf_perf, xgb_perf, lgbm_perf, lstm_perf
]

# Create comparison DataFrame
results = pd.DataFrame({
    'Model': model_names,
    'MSE': [p[0] for p in performance],
    'MAE': [p[1] for p in performance],
    'R²': [p[2] for p in performance]
})

# Sort by R² (descending)
results = results.sort_values('R²', ascending=False)

# Display results
print("\n## Model Performance Comparison ##")
display(results)

test_dates = returns.index[-len(X_test_seq):]
returns.loc[test_dates, 'LSTM_Pred'] = lstm_predictions  # New column for predictions

returns['Signal'] = 0
returns.loc[returns['LSTM_Pred'] > 0.005, 'Signal'] = 1    # Buy if prediction > 0.5%
returns.loc[returns['LSTM_Pred'] < -0.005, 'Signal'] = -1  # Sell if prediction < -0.5%

# Avoid lookahead bias by executing next day
returns['Strategy_Return'] = returns['Signal'].shift(1) * returns['Actual_5d_Return']
returns.dropna(subset=['Strategy_Return'], inplace=True)  # Clean NaN from shift

# Cumulative returns
plt.figure(figsize=(12, 6))
(1 + returns['Actual_5d_Return']).cumprod().plot(label='Buy & Hold')
(1 + returns['Strategy_Return']).cumprod().plot(label='LSTM Strategy')
plt.title('5-Day Returns: LSTM vs Buy & Hold')
plt.legend()
plt.show()

# Win rate
win_rate = (returns['Strategy_Return'] > 0).mean()

# Sharpe ratio (annualized)
sharpe = np.sqrt(252/5) * returns['Strategy_Return'].mean() / returns['Strategy_Return'].std()

print(f"Win Rate: {win_rate:.2%}")
print(f"Sharpe Ratio: {sharpe:.2f}")

# Analyze trades
positive_trades = returns[returns['Strategy_Return'] > 0]
negative_trades = returns[returns['Strategy_Return'] < 0]

print(f"Avg. Winning Trade: {positive_trades['Strategy_Return'].mean():.2%}")
print(f"Avg. Losing Trade: {negative_trades['Strategy_Return'].mean():.2%}")

from scipy.optimize import minimize_scalar

def objective(threshold):
    # Generate signals as a Pandas Series
    signals = pd.Series(
        np.where(
            returns['LSTM_Pred'] > threshold, 1,
            np.where(returns['LSTM_Pred'] < -threshold, -1, 0)
        ),
        index=returns.index  # very important for alignment
    )

    strat_returns = signals.shift(1) * returns['Actual_5d_Return']
    return -np.mean(strat_returns)  # We want to maximize returns, so minimize negative

# Run optimization
result = minimize_scalar(objective, bounds=(0, 0.1), method='bounded')
optimal_threshold = result.x
print(f"Optimal threshold: {optimal_threshold:.4f}")

# Scale position size by prediction confidence
returns['Position'] = returns['LSTM_Pred'].clip(-1, 1)  # Normalize to [-1, 1]
returns['Strategy_Return'] = returns['Position'].shift(1) * returns['Actual_5d_Return']

# Stop-loss at 2x avg. loss
avg_loss = negative_trades['Strategy_Return'].mean()
returns['Strategy_Return'] = np.where(
    returns['Strategy_Return'] < 2 * avg_loss,
    2 * avg_loss,
    returns['Strategy_Return']
)

# After optimizations
win_rate = (returns['Strategy_Return'] > 0).mean()
sharpe = np.sqrt(252/5) * returns['Strategy_Return'].mean() / returns['Strategy_Return'].std()

print(f"New Win Rate: {win_rate:.2%}")
print(f"New Sharpe Ratio: {sharpe:.2f}")































































































